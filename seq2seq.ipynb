{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bb55c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 16:21:52.710913: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-19 16:21:53.219037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-19 16:21:53.455116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-19 16:21:53.534786: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-19 16:21:53.928047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-19 16:21:56.467129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from itertools import compress\n",
    "torch.set_printoptions(sci_mode=False, threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and Preprocess Data by line\n",
    "def read_txt(txt_path):\n",
    "  with open(txt_path, 'r') as f:\n",
    "    txt_string = f.readlines()\n",
    "  return txt_string\n",
    "\n",
    "poem_list = []\n",
    "nump_poems = 13853\n",
    "for i in range(nump_poems+1):\n",
    "    txt_string = read_txt('Poems/'+str(i)+'.txt')\n",
    "    # print(txt_string)\n",
    "    # split_poem = [ [y.lower() for y in sentence.split(' ') if y] for sentence in txt_string]\n",
    "    poem = ''\n",
    "    for i in range(len(txt_string)):\n",
    "      if txt_string[i] == '\\n':\n",
    "        txt_string[i] = ''\n",
    "        continue\n",
    "      if txt_string[i].count('\\n') == 1 and len(txt_string[i]) > 2:\n",
    "         txt_string[i] = txt_string[i][:-1] + ' \\n '\n",
    "      poem += txt_string[i]\n",
    "    poem_list.append(poem)\n",
    "\n",
    "title_list = []\n",
    "for i in range(nump_poems+1):\n",
    "    txt_string = read_txt('Titles/'+str(i)+'.txt')\n",
    "    # print(txt_string)\n",
    "    # split_poem = [ [y.lower() for y in sentence.split(' ') if y] for sentence in txt_string]\n",
    "    title = ''\n",
    "    for i in range(len(txt_string)):\n",
    "      if txt_string[i] == '\\n':\n",
    "        txt_string[i] = ''\n",
    "        continue\n",
    "      if txt_string[i].count('\\n') == 1 and len(txt_string[i]) > 2:\n",
    "         txt_string[i] = txt_string[i][:-1] + ' \\n '\n",
    "      title += txt_string[i]\n",
    "    title_list.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8591d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Data by line for poem line pairs\n",
    "def clean_line(line):\n",
    "    if line.count('\\n') == 1 and len(line) > 2:\n",
    "        line = line[:-1] + ' \\n '\n",
    "    return line\n",
    "    \n",
    "        \n",
    "poem_pairs = []\n",
    "for i in range(nump_poems+1):\n",
    "    txt_string = read_txt('Poems/'+str(i)+'.txt')\n",
    "    for x in range(len(txt_string)):\n",
    "        if(x!=(len(txt_string)-1)):\n",
    "            line = txt_string[x]\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "            line = clean_line(line)\n",
    "            next_idx = x+1\n",
    "            next_line = txt_string[next_idx]\n",
    "            while next_line == '\\n' and next_idx!=(len(txt_string)-1):\n",
    "                next_idx += 1\n",
    "                next_line = txt_string[next_idx]\n",
    "            next_line = clean_line(next_line)\n",
    "\n",
    "            line_pair = (line, next_line)\n",
    "        poem_pairs.append(line_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating entire corpus\n",
    "for i in range(len(poem_list)):\n",
    "    with open(\"revised_corpus.txt\", 'a') as f:\n",
    "        f.write(poem_list[i])\n",
    "for i in range(len(title_list)):\n",
    "    with open(\"title_corpus.txt\", 'a') as f:\n",
    "        f.write(title_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657aad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer parameters\n",
    "VOCAB_SIZE = 50000\n",
    "MIN_FREQUENCY = 10\n",
    "LIMIT_ALPHABET = 6000 # How many initial characters to look at\n",
    "SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "poem_tokenizer_output_dir = Path(f'poem_vocab_{VOCAB_SIZE}')\n",
    "poem_tokenizer_output_dir.mkdir(exist_ok=True)\n",
    "title_tokenizer_output_dir = Path(f'title_vocab_{VOCAB_SIZE}')\n",
    "title_tokenizer_output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Train Tokenizer ---\n",
    "\n",
    "# poem_tokenizer_trainer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
    "\n",
    "# print(\"Training tokenizer...\")\n",
    "# poem_tokenizer_trainer.train(\n",
    "#     files=['revised_corpus.txt'],\n",
    "#     vocab_size=VOCAB_SIZE,\n",
    "#     min_frequency=MIN_FREQUENCY,\n",
    "#     limit_alphabet=LIMIT_ALPHABET,\n",
    "#     show_progress=True,\n",
    "#     special_tokens=SPECIAL_TOKENS\n",
    "# )\n",
    "# poem_tokenizer_trainer.save_model(str(poem_tokenizer_output_dir))\n",
    "# print(f\"poem tokenizer saved to: {poem_tokenizer_output_dir}\")\n",
    "\n",
    "# title_tokenizer_trainer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
    "\n",
    "# print(\"Training tokenizer...\")\n",
    "# title_tokenizer_trainer.train(\n",
    "#     files=['revised_corpus.txt'],\n",
    "#     vocab_size=VOCAB_SIZE,\n",
    "#     min_frequency=MIN_FREQUENCY,\n",
    "#     limit_alphabet=LIMIT_ALPHABET,\n",
    "#     show_progress=True,\n",
    "#     special_tokens=SPECIAL_TOKENS\n",
    "# )\n",
    "# title_tokenizer_trainer.save_model(str(title_tokenizer_output_dir))\n",
    "# print(f\"title tokenizer saved to: {title_tokenizer_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e90da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    str(poem_tokenizer_output_dir),\n",
    "    strip_accents=False,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "title_tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    str(title_tokenizer_output_dir),\n",
    "    strip_accents=False,\n",
    "    lowercase=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc69d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset for poems and titles\n",
    "#Create Dataset\n",
    "class Dataset():\n",
    "    def __init__(self, txt, title, txt_tokenizer, title_tokenizer, max_length):\n",
    "        self.poems = txt\n",
    "        self.titles = title\n",
    "        self.txt_tokenizer = txt_tokenizer\n",
    "        self.title_tokenizer = title_tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.poems))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        poem = self.poems[idx]\n",
    "        title = self.titles[idx]\n",
    "        sentence_in_token = self.txt_tokenizer.encode(poem, add_special_tokens=True, truncation=True, max_length=self.max_length)\n",
    "        title_in_token = self.title_tokenizer.encode(title, add_special_tokens=True, truncation=False)\n",
    "        source = title_in_token\n",
    "        target_output = sentence_in_token[:-1]\n",
    "        target_shifted = sentence_in_token[1:]\n",
    "        return torch.tensor(source), torch.tensor(target_output), torch.tensor(target_shifted)\n",
    "dataset = Dataset(poem_list, title_list, poem_tokenizer, title_tokenizer, 200)\n",
    "len(dataset)\n",
    "\n",
    "# Test Dataset\n",
    "# input, targets = dataset[0]\n",
    "# print(f\"  Source IDs: {input}\")\n",
    "# print(f\"  Source Decoded: {tokenizer.decode(input)}\")\n",
    "# print(f\"  Source IDs: {targets}\")\n",
    "# print(f\"  Source Decoded: {tokenizer.decode(targets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386917"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset for pairs of lines in poems\n",
    "class Poem_pairs_Dataset():\n",
    "    def __init__(self, pairs, txt_tokenizer, max_length=100):\n",
    "        self.pairs = pairs\n",
    "        self.txt_tokenizer = txt_tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.pairs))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src_line = self.pairs[idx][0]\n",
    "        tgt_line = self.pairs[idx][1]\n",
    "        src_in_token = self.txt_tokenizer.encode(src_line, add_special_tokens=True, truncation=False, max_length=100)\n",
    "        tgt_in_token = self.txt_tokenizer.encode(tgt_line, add_special_tokens=True, truncation=False, max_length=100)\n",
    "        source = src_in_token\n",
    "        target_output = tgt_in_token[:-1]\n",
    "        target_shifted = tgt_in_token[1:]\n",
    "        return torch.tensor(source), torch.tensor(target_output), torch.tensor(target_shifted)\n",
    "\n",
    "pairset = Poem_pairs_Dataset(poem_pairs, poem_tokenizer)\n",
    "len(pairset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "182a8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collate Function\n",
    "def collate_fn(raw_batch):\n",
    "    source, target, shifted_target = zip(*raw_batch)\n",
    "    return nn.utils.rnn.pack_sequence(source, enforce_sorted=False), nn.utils.rnn.pack_sequence(target, enforce_sorted=False), nn.utils.rnn.pack_sequence(shifted_target, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef7e2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainset and valid set\n",
    "train_set_len = int(0.9 * len(dataset))\n",
    "valid_set_len = len(dataset) - train_set_len\n",
    "train_set, valid_set  = torch.utils.data.random_split(dataset, [train_set_len, valid_set_len])\n",
    "#Pair dataset\n",
    "pair_train_set_len = int(0.9 * len(pairset))\n",
    "pair_valid_set_len = len(pairset) - pair_train_set_len\n",
    "pair_train_set, pair_valid_set  = torch.utils.data.random_split(pairset, [pair_train_set_len, pair_valid_set_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c3df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU Seq2Seq Language Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, tgt_tokenizer, src_tokenizer, hidden_size, layers, dropout_p=.1):\n",
    "        super().__init__()\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.layers = layers\n",
    "        self.tgt_vocab_size = self.tgt_tokenizer.vocab_size\n",
    "        self.src_vocab_size = self.src_tokenizer.vocab_size\n",
    "        self.src_emb = nn.Embedding(num_embeddings=self.src_vocab_size, embedding_dim=hidden_size)\n",
    "        self.tgt_emb = nn.Embedding(num_embeddings=self.tgt_vocab_size, embedding_dim=hidden_size)\n",
    "        self.encoder = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=layers, bidirectional=True, batch_first=True)\n",
    "        self.decoder = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.proj = nn.Linear(in_features=hidden_size, out_features=self.tgt_vocab_size)\n",
    "    def forward(self, x, y):\n",
    "        #Encoder\n",
    "        emb_x = nn.utils.rnn.PackedSequence(self.src_emb(x.data), batch_sizes=x.batch_sizes, sorted_indices=x.sorted_indices, unsorted_indices=x.unsorted_indices)\n",
    "        encode_output, encode_hidden = self.encoder(emb_x)\n",
    "        encode_hidden_sum = encode_hidden.reshape(self.layers, 2, encode_hidden.shape[1], -1).mean(dim=1)\n",
    "        hidden_mean = encode_output.data.reshape(-1, 2, encode_hidden_sum.shape[-1]).mean(1)\n",
    "        encode_output = nn.utils.rnn.PackedSequence(hidden_mean, x[1], x[2], x[3])\n",
    "\n",
    "        #Decoder\n",
    "        emb_y = nn.utils.rnn.PackedSequence(self.tgt_emb(y.data), batch_sizes=y.batch_sizes, sorted_indices=y.sorted_indices, unsorted_indices=y.unsorted_indices)\n",
    "        out, decoder_hidden = self.decoder(emb_y, encode_hidden_sum)\n",
    "        logits = self.proj(out.data)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        probs = nn.utils.rnn.PackedSequence(probs, batch_sizes=y.batch_sizes, sorted_indices=y.sorted_indices, unsorted_indices=y.unsorted_indices)\n",
    "  \n",
    "        return probs\n",
    "    #Encode during inference\n",
    "    def encode(self, x):\n",
    "        emb_x = self.src_emb(x.data)\n",
    "        encode_output, encode_hidden = self.encoder(emb_x)\n",
    "        encode_hidden_sum = encode_hidden.reshape(self.layers, 2, encode_hidden.shape[1], -1).mean(dim=1)\n",
    "        return encode_hidden_sum\n",
    "    #Decode during inference\n",
    "    def decode(self, x, enc_hidden):\n",
    "        emb_y  = self.tgt_emb(x.data)\n",
    "        out, decoder_hidden = self.decoder(emb_y, enc_hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer\n",
    "class Trainer():\n",
    "    def __init__(self, model, device, learningrate, train_set, valid_set, model_name):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learningrate)\n",
    "        self.train_set = train_set\n",
    "        self.valid_set = valid_set\n",
    "        self.model_name = model_name\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        self.valid_loss = []\n",
    "        self.valid_acc = []\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.best_valid_acc = 0.0\n",
    "\n",
    "    def nll_loss(self, pred, target, eps=1e-8):\n",
    "        '''\n",
    "        for PackedSequence, the input is 2D tensor\n",
    "\n",
    "        predicted_prob_distribution has a shape of [num_entire_tokens_in_the_batch x vocab_size]\n",
    "        indices_of_correct_token has a shape of [num_entire_tokens_in_the_batch]\n",
    "        '''\n",
    "\n",
    "        if pred.ndim == 3:\n",
    "            pred = pred.flatten(0, 1)\n",
    "        if target.ndim == 2:\n",
    "            target = target.flatten(0, 1)\n",
    "        assert pred.ndim == 2\n",
    "        assert target.ndim == 1\n",
    "        return -torch.log(pred[torch.arange(len(target)), target] + eps).mean()\n",
    "    \n",
    "    def validation(self):\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            total_loss = []\n",
    "            total_acc = []\n",
    "            for batch in self.valid_set:\n",
    "                src, tgt, shifted_tgt = batch\n",
    "                src = src.to('cuda')\n",
    "                tgt = tgt.to('cuda')\n",
    "                shifted_tgt = shifted_tgt.to('cuda')\n",
    "                prob = self.model(src, tgt) \n",
    "                loss = self.nll_loss(prob.data, shifted_tgt.data)\n",
    "                total_loss.append(loss.item())\n",
    "                predicts = torch.argmax(prob.data, dim=-1)\n",
    "                num_acc_pred = (predicts == shifted_tgt.data).sum()\n",
    "                total_acc.append(num_acc_pred.item()/len(predicts))\n",
    "        return (sum(total_loss)/len(total_loss)), (sum(total_acc)/len(total_acc))\n",
    "\n",
    "    def train(self, n_epoch):\n",
    "        for i in range(n_epoch):\n",
    "            self.model.train()\n",
    "            for batch in tqdm(self.train_set):\n",
    "                src, tgt, shifted_tgt = batch\n",
    "                src = src.to('cuda')\n",
    "                tgt = tgt.to('cuda')\n",
    "                shifted_tgt = shifted_tgt.to('cuda')\n",
    "                prob = self.model(src, tgt) \n",
    "                loss = self.nll_loss(prob.data, shifted_tgt.data)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                self.train_loss.append(loss.item())\n",
    "    \n",
    "            valid_loss, valid_acc = self.validation()\n",
    "            if valid_acc > self.best_valid_acc:\n",
    "                self.best_valid_acc = valid_acc\n",
    "                torch.save(self.model.state_dict(), f'models/{self.model_name}_best.pt')\n",
    "                print(f\"Saving model at epoch {i}, valid acc: {valid_acc}, valid loss: {valid_loss}\")\n",
    "            self.valid_loss.append(valid_loss)\n",
    "            self.valid_acc.append(valid_acc)\n",
    "            \n",
    "        plt.figure(1)\n",
    "        plt.plot(self.valid_acc)\n",
    "        plt.title(\"Accuracy over batch\")\n",
    "        plt.savefig(f\"graphs/{self.model_name}_best_valid_acc\")\n",
    "        plt.figure(2)\n",
    "        plt.title(\"Loss over batch\")\n",
    "        plt.plot(self.train_loss)\n",
    "        plt.savefig(f\"graphs/{self.model_name}_best_train_loss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979783ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Setting Params\n",
    "device = 'cuda'\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle= True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "pair_train_loader = DataLoader(pair_train_set, batch_size=64, shuffle= True, collate_fn=collate_fn)\n",
    "pair_valid_loader = DataLoader(pair_valid_set, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990d5fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c729b008ef4504a4f71164e721ee25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load('pathfinder_seq2seq_model_512_l2_best.pt', weights_only=True))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, device\u001b[38;5;241m=\u001b[39mdevice, learningrate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,train_set\u001b[38;5;241m=\u001b[39mtrain_loader, valid_set\u001b[38;5;241m=\u001b[39mvalid_loader, model_name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 62\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(src, tgt) \n\u001b[1;32m     61\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnll_loss(prob\u001b[38;5;241m.\u001b[39mdata, shifted_tgt\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 62\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "name = 'title_seq2seq_model_512_l2_bs32'\n",
    "model = Seq2Seq(src_tokenizer=title_tokenizer, tgt_tokenizer=poem_tokenizer, hidden_size=512, layers=2, dropout_p=.2)\n",
    "# model.load_state_dict(torch.load('pathfinder_seq2seq_model_512_l2_best.pt', weights_only=True))\n",
    "trainer = Trainer(model=model, device=device, learningrate=0.001,train_set=train_loader, valid_set=valid_loader, model_name=name)\n",
    "trainer.train(n_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef6a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72a1445b0730>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainer.train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4762f71",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3612036b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (src_emb): Embedding(30446, 512)\n",
       "  (tgt_emb): Embedding(30447, 512)\n",
       "  (encoder): GRU(512, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (decoder): GRU(512, 512, num_layers=2, batch_first=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (proj): Linear(in_features=512, out_features=30447, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_model = Seq2Seq(src_tokenizer=title_tokenizer, tgt_tokenizer=poem_tokenizer, hidden_size=512, layers=2)\n",
    "infer_model.load_state_dict(torch.load('models/pathfinder_seq2seq_model_512_l2_best.pt', weights_only=True))\n",
    "infer_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd048ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_p_sampling(logits, current_decoder_token, rep_pen=0.1, temperature=1.0, top_p=0.9):\n",
    "    # Ensure logits are a PyTorch tensor and move to DEVICE\n",
    "\n",
    "    # Apply temperature scaling\n",
    "    scaled_logits = logits / temperature\n",
    "\n",
    "    # Convert logits to probabilities using softmax\n",
    "    probabilities = torch.softmax(scaled_logits, dim=-1)\n",
    "    for tok_idx in current_decoder_token[0]:\n",
    "                    # print(f\"before: {probabilities[tok_idx]}\")\n",
    "                    probabilities[3] *= 1\n",
    "                    probabilities[tok_idx] *= rep_pen\n",
    "                    # print(f\"after: {probabilities[tok_idx]}\")\n",
    "    # Sort probabilities and compute cumulative sum\n",
    "    sorted_indices = torch.argsort(probabilities, descending=True)\n",
    "    sorted_probabilities = probabilities[sorted_indices]\n",
    "    cumulative_probabilities = torch.cumsum(sorted_probabilities, dim=-1)\n",
    "\n",
    "    # Apply top-p filtering\n",
    "    indices_to_keep = cumulative_probabilities <= top_p\n",
    "    truncated_probabilities = sorted_probabilities[indices_to_keep]\n",
    "\n",
    "    # Rescale the probabilities\n",
    "    truncated_probabilities /= torch.sum(truncated_probabilities)\n",
    "\n",
    "    # Convert to numpy arrays for random choice\n",
    "    truncated_probabilities = truncated_probabilities.cpu().numpy()\n",
    "    sorted_indices = sorted_indices.cpu().numpy()\n",
    "    indices_to_keep = indices_to_keep.cpu().numpy()\n",
    "\n",
    "    # Sample from the truncated distribution\n",
    "    if not indices_to_keep.any():\n",
    "        # Handle the empty case - for example, using regular sampling without top-p\n",
    "        probabilities = torch.softmax(logits / temperature, dim=-1)\n",
    "        next_word_index = torch.multinomial(probabilities, 1).item()\n",
    "    else:\n",
    "        # Existing sampling process\n",
    "        next_word_index = np.random.choice(sorted_indices[indices_to_keep], p=truncated_probabilities)\n",
    "\n",
    "    return torch.tensor(next_word_index).to('cpu')\n",
    "\n",
    "def generate_text(model, seed_text, next_words,lines, temperature=1.0, top_p=0.9, rep_pen = 0.1):\n",
    "    model.to('cpu')\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        input_tokens = title_tokenizer.encode(seed_text)\n",
    "        \n",
    "        predicted_tokens = []\n",
    "        input_tensor = torch.LongTensor(input_tokens).unsqueeze(0)\n",
    "        enc_out = model.encode(input_tensor)\n",
    "        current_decoder_token = torch.LongTensor([[2]])\n",
    "        for _ in range(lines):\n",
    "            \n",
    "\n",
    "            for _ in range(next_words):\n",
    "                decoder_out = model.decode(current_decoder_token, enc_out)\n",
    "                logit = model.proj(decoder_out[0, -1])\n",
    "                sampled_token = top_p_sampling(logit, current_decoder_token, rep_pen, temperature, top_p)\n",
    "                # sampled_token = torch.argmax(logit, dim=-1)\n",
    "                current_decoder_token = torch.tensor(current_decoder_token[0].tolist() + [sampled_token], dtype=torch.long).unsqueeze(0)\n",
    "                # output_word = poem_tokenizer.decode(sampled_token.item())\n",
    "                if sampled_token == 3: ## end of sentence token\n",
    "                    break\n",
    "            newest_tokens = current_decoder_token.squeeze().tolist()[1:-1]\n",
    "            # input_tokens = title_tokenizer.encode(seed_text)\n",
    "            input_tensor = torch.LongTensor(newest_tokens).unsqueeze(0)\n",
    "            current_decoder_token = torch.LongTensor([[2]])\n",
    "            predicted_tokens.append(newest_tokens)\n",
    "    output_poem = \"\"\n",
    "    for line in predicted_tokens:\n",
    "        line = poem_tokenizer.decode(line)\n",
    "        output_poem += line + ' \\n'\n",
    "\n",
    "    return input_tokens, predicted_tokens, output_poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00289cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [CLS] sunset on the beach [SEP]\n",
      "output: \n",
      " whole roads fell on the hill the scarcity at \n",
      "thus on the radio stood tiptoe \n",
      "on full picture the dusk falls whitenover the deep into thunder \n",
      "stony satin the yellow spilled foam until until \n",
      "fish piles the bell extremely swoop \n",
      "fury of the canvas striking on \n",
      "houses fell over the edges on the road \n",
      "upturned corpses \n",
      "darkest on the deck break south a foot \n",
      "faint breaking on the crooked evening \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_tokens, pred_tokens, gen_poem = generate_text(infer_model, \"sunset on the beach\", next_words=30, lines=10, temperature=1.4, top_p=0.7, rep_pen=1)\n",
    "print(f\"input: {title_tokenizer.decode(input_tokens)}\")\n",
    "print(f\"output: \\n {gen_poem}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
